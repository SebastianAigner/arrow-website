"use strict";(self.webpackChunkarrow_website=self.webpackChunkarrow_website||[]).push([[3232],{30233:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>l,frontMatter:()=>r,metadata:()=>a,toc:()=>p});var o=n(85893),s=n(11151);const r={title:"With Kafka",sidebar_position:3},i="SuspendApp with Kafka",a={id:"ecosystem/suspendapp/kafka",title:"With Kafka",description:"When streaming records from Kafka we need to commit (acknowledge) the offset of the records",source:"@site/content/docs/ecosystem/suspendapp/kafka.md",sourceDirName:"ecosystem/suspendapp",slug:"/ecosystem/suspendapp/kafka",permalink:"/ecosystem/suspendapp/kafka",draft:!1,unlisted:!1,editUrl:"https://github.com/arrow-kt/arrow-website/edit/main/content/docs/ecosystem/suspendapp/kafka.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"With Kafka",sidebar_position:3},sidebar:"ecosystemSidebar",previous:{title:"With Ktor",permalink:"/ecosystem/suspendapp/ktor"},next:{title:"Analysis",permalink:"/ecosystem/analysis/"}},c={},p=[];function d(e){const t={a:"a",code:"code",em:"em",h1:"h1",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"suspendapp-with-kafka",children:"SuspendApp with Kafka"}),"\n",(0,o.jsxs)(t.p,{children:["When streaming ",(0,o.jsx)(t.em,{children:"records"})," from Kafka we need to ",(0,o.jsx)(t.em,{children:"commit"})," (acknowledge) the offset of the ",(0,o.jsx)(t.em,{children:"records"}),"\nwe've processed.\nThe official recommendation for doing this is committing offsets in batches, so we typically don't send the commit event\nto Kafka for every processed record.\nInstead, we commit the offset every 5 seconds (or every x records, 5s is default)."]}),"\n",(0,o.jsxs)(t.p,{children:["Imagine the application getting stopped after 4,5 seconds, either by ",(0,o.jsx)(t.em,{children:"Ctrl+C"})," or K8S or another type of\ncontainerization.\nWe could've processed thousands, or tens of thousands of events.\nIf we don't commit these offsets before shutting down we'd have to re-process all the events."]}),"\n",(0,o.jsxs)(t.p,{children:["We can easily prevent this with SuspendApp, and ",(0,o.jsx)(t.a,{href:"https://github.com/nomisRev/kotlin-kafka",children:"kotlin-kafka"}),"\nor ",(0,o.jsx)(t.a,{href:"https://github.com/reactor/reactor-kafka",children:"reactor-kafka"}),".\nBoth these high-level Kafka libraries guarantee committing offsets upon termination of the stream, this includes\ncancellation!\nIn the example below, all calls to ",(0,o.jsx)(t.code,{children:"acknowledge"})," will be committed to Kafka before the SuspendApp terminates when\nreceiving ",(0,o.jsx)(t.code,{children:"SIGTERM"})," or ",(0,o.jsx)(t.code,{children:"SIGINT"}),"."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-kotlin",children:'import kotlinx.coroutines.flow.collect\nimport kotlinx.coroutines.flow.map\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport io.github.nomisRev.kafka.receiver.KafkaReceiver\nimport io.github.nomisRev.kafka.receiver.ReceiverSettings\nimport arrow.continuations.SuspendApp\n\nfun main() = SuspendApp {\n  val settings: ReceiverSettings<Nothing, String> = ReceiverSettings(\n    bootstrapServers = bootstrapServers,\n    groupId = "group-id",\n    valueDeserializer = StringDeserializer()\n  )\n  KafkaReceiver(settings)\n    .receive(topicName)\n    .map { record ->\n      println("${record.key()} -> ${record.value()}")\n      record.offset.acknowledge()\n    }.collect()\n}\n'})})]})}function l(e={}){const{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},11151:(e,t,n)=>{n.d(t,{Z:()=>a,a:()=>i});var o=n(67294);const s={},r=o.createContext(s);function i(e){const t=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(r.Provider,{value:t},e.children)}}}]);